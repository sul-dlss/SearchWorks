---
format_hsim:
- Book
id: in00000382380
hashed_id_ssi: a9c7e8a69a84d3a856d01bb99ac81dfd
marc_json_struct:
- '{"leader":"02586nam a22003493i 4500","fields":[{"001":"in00000382380"},{"006":"m        d        "},{"007":"cr
  un         "},{"008":"250314t20252025cau     om    000 0 eng d"},{"005":"20250614181901.0"},{"035":{"ind1":"
  ","ind2":" ","subfields":[{"a":"dorbp098kt2063"}]}},{"035":{"ind1":" ","ind2":"
  ","subfields":[{"a":"(OCoLC-M)1509352419"}]}},{"040":{"ind1":" ","ind2":" ","subfields":[{"a":"CSt"},{"b":"eng"},{"e":"rda"},{"c":"CSt"},{"d":"UtOrBLW"}]}},{"100":{"ind1":"1","ind2":"
  ","subfields":[{"a":"Mutlu, Onur Cezmi,"},{"e":"author."}]}},{"245":{"ind1":"1","ind2":"0","subfields":[{"a":"Adaptation
  and regularization of deep neural networks under temporal smoothness assumption
  /"},{"c":"Onur Cezmi Mutlu"}]}},{"264":{"ind1":" ","ind2":"1","subfields":[{"a":"[Stanford,
  California] :"},{"b":"[Stanford University],"},{"c":"2025"}]}},{"264":{"ind1":"
  ","ind2":"4","subfields":[{"c":"©2025"}]}},{"300":{"ind1":" ","ind2":" ","subfields":[{"a":"1
  online resource"}]}},{"336":{"ind1":" ","ind2":" ","subfields":[{"a":"text"},{"2":"rdacontent"}]}},{"337":{"ind1":"
  ","ind2":" ","subfields":[{"a":"computer"},{"2":"rdamedia"}]}},{"338":{"ind1":"
  ","ind2":" ","subfields":[{"a":"online resource"},{"2":"rdacarrier"}]}},{"500":{"ind1":"
  ","ind2":" ","subfields":[{"a":"Submitted to the Department of Electrical Engineering"}]}},{"502":{"ind1":"
  ","ind2":" ","subfields":[{"g":"Thesis"},{"b":"Ph.D."},{"c":"Stanford University"},{"d":"2025"}]}},{"520":{"ind1":"3","ind2":"
  ","subfields":[{"a":"Deep neural networks face challenges in real-world deployment
  due to domain shifts and computational constraints. This dissertation presents TempT,
  a self-supervised method that leverages temporal smoothness in predictions to improve
  model robustness without labeled data. By suppressing high-frequency fluctuations,
  TempT enhances generalization, particularly in sequential tasks. We also explore
  selective adaptation using persistent homology to determine when adaptation is beneficial
  and introduce a regularization framework that enforces smoothness constraints during
  training. Experimental results demonstrate TempT''s effectiveness over existing
  adaptation techniques while maintaining efficiency for edge computing and privacy-sensitive
  applications. This work unifies domain adaptation, self-supervised learning, and
  regularization to provide a scalable solution for deep learning in dynamic environments"}]}},{"700":{"ind1":"1","ind2":"
  ","subfields":[{"a":"Wall, Dennis Paul,"},{"e":"degree supervisor."},{"4":"ths"},{"0":"http://id.loc.gov/authorities/names/no2023129516"}]}},{"700":{"ind1":"1","ind2":"
  ","subfields":[{"a":"Nishimura, Dwight George,"},{"e":"degree committee member."},{"4":"ths"},{"0":"http://id.loc.gov/authorities/names/n88603441"}]}},{"700":{"ind1":"1","ind2":"
  ","subfields":[{"a":"Pauly, John"},{"q":"(John M.),"},{"e":"degree committee member."},{"4":"ths"},{"0":"http://id.loc.gov/authorities/names/no2018038153"}]}},{"710":{"ind1":"2","ind2":"
  ","subfields":[{"a":"Stanford University."},{"b":"School of Engineering."},{"0":"http://id.loc.gov/authorities/names/n82220006"}]}},{"710":{"ind1":"2","ind2":"
  ","subfields":[{"a":"Stanford University."},{"b":"Department of Electrical Engineering."},{"0":"http://id.loc.gov/authorities/names/nr2002030762"}]}},{"856":{"ind1":"4","ind2":"0","subfields":[{"u":"https://purl.stanford.edu/bp098kt2063"},{"x":"SDR-PURL"},{"x":"item"},{"x":"rights:world"}]}},{"999":{"ind1":"f","ind2":"f","subfields":[{"s":"f8bba27b-113a-42f8-ae45-d43dd79c0f9c"},{"i":"4991c685-3832-4811-ac32-4843e33f36ea"}]}}]}'
all_search: 'Mutlu, Onur Cezmi, author. Adaptation and regularization of deep neural
  networks under temporal smoothness assumption / Onur Cezmi Mutlu [Stanford, California]
  : [Stanford University], 2025 ©2025 1 online resource text rdacontent computer rdamedia
  online resource rdacarrier Submitted to the Department of Electrical Engineering
  Thesis Ph.D. Stanford University 2025 Deep neural networks face challenges in real-world
  deployment due to domain shifts and computational constraints. This dissertation
  presents TempT, a self-supervised method that leverages temporal smoothness in predictions
  to improve model robustness without labeled data. By suppressing high-frequency
  fluctuations, TempT enhances generalization, particularly in sequential tasks. We
  also explore selective adaptation using persistent homology to determine when adaptation
  is beneficial and introduce a regularization framework that enforces smoothness
  constraints during training. Experimental results demonstrate TempT''s effectiveness
  over existing adaptation techniques while maintaining efficiency for edge computing
  and privacy-sensitive applications. This work unifies domain adaptation, self-supervised
  learning, and regularization to provide a scalable solution for deep learning in
  dynamic environments Wall, Dennis Paul, degree supervisor. ths http://id.loc.gov/authorities/names/no2023129516
  Nishimura, Dwight George, degree committee member. ths http://id.loc.gov/authorities/names/n88603441
  Pauly, John (John M.), degree committee member. ths http://id.loc.gov/authorities/names/no2018038153
  Stanford University. School of Engineering. http://id.loc.gov/authorities/names/n82220006
  Stanford University. Department of Electrical Engineering. http://id.loc.gov/authorities/names/nr2002030762
  https://purl.stanford.edu/bp098kt2063 SDR-PURL item rights:world'
title_245a_search: Adaptation and regularization of deep neural networks under temporal
  smoothness assumption /
title_245_search: Adaptation and regularization of deep neural networks under temporal
  smoothness assumption /
title_245a_display: Adaptation and regularization of deep neural networks under temporal
  smoothness assumption
title_245c_display: Onur Cezmi Mutlu
title_display: Adaptation and regularization of deep neural networks under temporal
  smoothness assumption
title_full_display: Adaptation and regularization of deep neural networks under temporal
  smoothness assumption / Onur Cezmi Mutlu
title_sort: Adaptation and regularization of deep neural networks under temporal smoothness
  assumption
author_title_245ac_search:
- Adaptation and regularization of deep neural networks under temporal smoothness
  assumption / Onur Cezmi Mutlu
author_title_1xx_search:
- Mutlu, Onur Cezmi Adaptation and regularization of deep neural networks under temporal
  smoothness assumption /
author_title_search:
- Mutlu, Onur Cezmi Adaptation and regularization of deep neural networks under temporal
  smoothness assumption /
best_author_title_search: Mutlu, Onur Cezmi Adaptation and regularization of deep
  neural networks under temporal smoothness assumption /
author_1xx_search: Mutlu, Onur Cezmi,
author_7xx_search:
- Wall, Dennis Paul,
- Nishimura, Dwight George,
- Pauly, John (John M.),
- Stanford University. School of Engineering.
- Stanford University. Department of Electrical Engineering.
author_person_facet:
- Mutlu, Onur Cezmi
- Wall, Dennis Paul
- Nishimura, Dwight George
- Pauly, John (John M.)
author_other_facet:
- Stanford University. School of Engineering
- Stanford University. Department of Electrical Engineering
author_person_display:
- Mutlu, Onur Cezmi
author_person_full_display:
- Mutlu, Onur Cezmi, author.
author_sort: Mutlu Onur Cezmi Adaptation and regularization of deep neural networks
  under temporal smoothness assumption
author_authorities_ssim:
- http://id.loc.gov/authorities/names/no2023129516
- http://id.loc.gov/authorities/names/n88603441
- http://id.loc.gov/authorities/names/no2018038153
- http://id.loc.gov/authorities/names/n82220006
- http://id.loc.gov/authorities/names/nr2002030762
pub_search:
- "[Stanford, California] : [Stanford University]"
pub_display:
- "[Stanford, California] : [Stanford University]"
pub_country: California, United States
pub_date: '2025'
pub_date_search: '2025'
pub_date_sort: '2025'
pub_year_tisim:
- 2025
pub_year_ss: '2025'
publication_year_isi: 2025
copyright_year_isi: 2025
imprint_display:
- "[Stanford, California] : [Stanford University], 2025"
date_cataloged: '2025-03-17T00:00:00Z'
language:
- English
url_fulltext:
- https://purl.stanford.edu/bp098kt2063
oclc:
- '1509352419'
access_facet:
- Online
format_main_ssim:
- Book
genre_ssim:
- Thesis/Dissertation
physical:
- 1 online resource
summary_search:
- Deep neural networks face challenges in real-world deployment due to domain shifts
  and computational constraints. This dissertation presents TempT, a self-supervised
  method that leverages temporal smoothness in predictions to improve model robustness
  without labeled data. By suppressing high-frequency fluctuations, TempT enhances
  generalization, particularly in sequential tasks. We also explore selective adaptation
  using persistent homology to determine when adaptation is beneficial and introduce
  a regularization framework that enforces smoothness constraints during training.
  Experimental results demonstrate TempT's effectiveness over existing adaptation
  techniques while maintaining efficiency for edge computing and privacy-sensitive
  applications. This work unifies domain adaptation, self-supervised learning, and
  regularization to provide a scalable solution for deep learning in dynamic environments
summary_display:
- Deep neural networks face challenges in real-world deployment due to domain shifts
  and computational constraints. This dissertation presents TempT, a self-supervised
  method that leverages temporal smoothness in predictions to improve model robustness
  without labeled data. By suppressing high-frequency fluctuations, TempT enhances
  generalization, particularly in sequential tasks. We also explore selective adaptation
  using persistent homology to determine when adaptation is beneficial and introduce
  a regularization framework that enforces smoothness constraints during training.
  Experimental results demonstrate TempT's effectiveness over existing adaptation
  techniques while maintaining efficiency for edge computing and privacy-sensitive
  applications. This work unifies domain adaptation, self-supervised learning, and
  regularization to provide a scalable solution for deep learning in dynamic environments
stanford_work_facet_hsim:
- Thesis/Dissertation|Doctoral|Doctor of Philosophy (PhD)
stanford_dept_sim:
- School of Engineering
- Department of Electrical Engineering
holdings_library_code_ssim:
- SUL
library_code_facet_ssim:
- SUL
- SDR
building_facet:
- Stanford Digital Repository
managed_purl_urls:
- https://purl.stanford.edu/bp098kt2063
collection:
- sirsi
- folio
collection_search:
- sirsi
- folio
context_source_ssi: folio
context_input_name_ssi: "/dev/null"
context_input_modified_dtsi: '2024-12-12T06:30:53Z'
context_marc_fields_ssim:
- '001'
- '006'
- '007'
- '008'
- '005'
- '035'
- '040'
- '100'
- '245'
- '264'
- '300'
- '336'
- '337'
- '338'
- '500'
- '502'
- '520'
- '700'
- '710'
- '856'
- '999'
- 035a
- 040abecd
- 100ae
- 245ac
- 264abc
- 264c
- 300a
- 336a2
- 337a2
- 338a2
- 500a
- 502gbcd
- 520a
- 700ae40
- 700aqe40
- 710ab0
- 856uxxx
- 999si
- "?035a"
- "?040a"
- "?040b"
- "?040e"
- "?040c"
- "?040d"
- "?100a"
- "?100e"
- "?245a"
- "?245c"
- "?264a"
- "?264b"
- "?264c"
- "?300a"
- "?336a"
- "?3362"
- "?337a"
- "?3372"
- "?338a"
- "?3382"
- "?500a"
- "?502g"
- "?502b"
- "?502c"
- "?502d"
- "?520a"
- "?700a"
- "?700e"
- "?7004"
- "?7000"
- "?700q"
- "?710a"
- "?710b"
- "?7100"
- "?856u"
- "?856x"
- "?999s"
- "?999i"
bib_search: 'Mutlu, Onur Cezmi, author. Adaptation and regularization of deep neural
  networks under temporal smoothness assumption / Onur Cezmi Mutlu [Stanford, California]
  : [Stanford University], 2025 ©2025 Wall, Dennis Paul, degree supervisor. ths Nishimura,
  Dwight George, degree committee member. ths Pauly, John (John M.), degree committee
  member. ths Stanford University. School of Engineering. Stanford University. Department
  of Electrical Engineering. Book'
vern_bib_search: Book
uuid_ssi: 4991c685-3832-4811-ac32-4843e33f36ea
folio_json_struct:
- '{"instance":{"id":"4991c685-3832-4811-ac32-4843e33f36ea","hrid":"in00000382380","tags":{"tagList":[]},"notes":[{"note":"Submitted
  to the Department of Electrical Engineering","staffOnly":false,"instanceNoteTypeId":"6a2533a7-4de2-4e64-8466-074c2fa9308c"},{"note":"Thesis
  Ph.D. Stanford University 2025","staffOnly":false,"instanceNoteTypeId":"b73cc9c2-c9fa-49aa-964f-5ae1aa754ecd"},{"note":"Deep
  neural networks face challenges in real-world deployment due to domain shifts and
  computational constraints. This dissertation presents TempT, a self-supervised method
  that leverages temporal smoothness in predictions to improve model robustness without
  labeled data. By suppressing high-frequency fluctuations, TempT enhances generalization,
  particularly in sequential tasks. We also explore selective adaptation using persistent
  homology to determine when adaptation is beneficial and introduce a regularization
  framework that enforces smoothness constraints during training. Experimental results
  demonstrate TempT''s effectiveness over existing adaptation techniques while maintaining
  efficiency for edge computing and privacy-sensitive applications. This work unifies
  domain adaptation, self-supervised learning, and regularization to provide a scalable
  solution for deep learning in dynamic environments","staffOnly":false,"instanceNoteTypeId":"10e2e11b-450f-45c8-b09b-0f819999966e"}],"title":"Adaptation
  and regularization of deep neural networks under temporal smoothness assumption
  / Onur Cezmi Mutlu","series":[],"source":"MARC","_version":8,"editions":[],"metadata":{"createdDate":"2025-03-14T20:37:20.177Z","updatedDate":"2025-06-14T18:19:07.311Z","createdByUserId":"709fdac6-d3f3-5784-8839-fe36ad6ed0b3","updatedByUserId":"ffba9979-3f5d-4aac-a74f-18218dd2573f"},"statusId":"9634a5ab-9228-4703-baf2-4d12ebc77d56","subjects":[],"languages":["eng"],"indexTitle":"Adaptation
  and regularization of deep neural networks under temporal smoothness assumption
  /","identifiers":[{"value":"dorbp098kt2063","identifierTypeId":"7e591197-f335-4afb-bc6d-a6d76ca3bace"},{"value":"(OCoLC-M)1509352419","identifierTypeId":"439bfbae-75bc-4f74-9fc7-b2a2d47ce3ef"}],"publication":[{"role":"Publication","place":"[Stanford,
  California]","publisher":"[Stanford University]","dateOfPublication":"2025"},{"dateOfPublication":"©2025"}],"contributors":[{"name":"Mutlu,
  Onur Cezmi","primary":true,"contributorTypeId":"6e09d47d-95e2-4d8a-831b-f777b8ef6d81","contributorNameTypeId":"2b94c631-fca9-4892-a730-03ee529ffe2a"},{"name":"Wall,
  Dennis Paul","primary":false,"contributorTypeId":"cce475f7-ccfa-4e15-adf8-39f907788515","contributorNameTypeId":"2b94c631-fca9-4892-a730-03ee529ffe2a"},{"name":"Nishimura,
  Dwight George","primary":false,"contributorTypeId":"cce475f7-ccfa-4e15-adf8-39f907788515","contributorNameTypeId":"2b94c631-fca9-4892-a730-03ee529ffe2a"},{"name":"Pauly,
  John (John M.)","primary":false,"contributorTypeId":"cce475f7-ccfa-4e15-adf8-39f907788515","contributorNameTypeId":"2b94c631-fca9-4892-a730-03ee529ffe2a"},{"name":"Stanford
  University. School of Engineering","primary":false,"contributorNameTypeId":"2e48e713-17f3-4c13-a9f8-23845bb210aa"},{"name":"Stanford
  University. Department of Electrical Engineering","primary":false,"contributorNameTypeId":"2e48e713-17f3-4c13-a9f8-23845bb210aa"}],"catalogedDate":"2025-03-17","instanceTypeId":"6312d172-f0cf-40f6-b27d-9fa8feaf332f","previouslyHeld":false,"classifications":[],"instanceFormats":[],"electronicAccess":[{"uri":"https://purl.stanford.edu/bp098kt2063","name":"Resource","relationshipId":"f5d0068e-6272-458e-8a81-b85e7b9a14aa"}],"holdingsRecords2":[],"modeOfIssuanceId":"9d18a02f-5897-4c31-9106-c9abb5c7ae8b","publicationRange":[],"statisticalCodes":[],"alternativeTitles":[],"discoverySuppress":false,"instanceFormatIds":[],"statusUpdatedDate":"2025-03-17T23:27:57.476Z","statisticalCodeIds":["0f328803-cd6a-47c0-8e76-f3a775d56884","ae9ce864-f50c-47ce-a5f1-6579f7057fc5"],"administrativeNotes":[],"physicalDescriptions":["1
  online resource"],"publicationFrequency":[],"suppressFromDiscovery":false,"natureOfContentTermIds":[]},"po_lines":0}'
author_struct:
- creator:
  - link: Mutlu, Onur Cezmi,
    search: Mutlu, Onur Cezmi,
    post_text: author.
  contributors:
  - link: Wall, Dennis Paul,
    search: Wall, Dennis Paul,
    pre_text: ''
    post_text: degree supervisor. Thesis advisor
    authorities:
    - http://id.loc.gov/authorities/names/no2023129516
    rwo: []
  - link: Nishimura, Dwight George,
    search: Nishimura, Dwight George,
    pre_text: ''
    post_text: degree committee member. Thesis advisor
    authorities:
    - http://id.loc.gov/authorities/names/n88603441
    rwo: []
  - link: Pauly, John (John M.),
    search: Pauly, John (John M.),
    pre_text: ''
    post_text: degree committee member. Thesis advisor
    authorities:
    - http://id.loc.gov/authorities/names/no2018038153
    rwo: []
  - link: Stanford University. School of Engineering.
    search: Stanford University. School of Engineering.
    pre_text: ''
    post_text: ''
    authorities:
    - http://id.loc.gov/authorities/names/n82220006
    rwo: []
  - link: Stanford University. Department of Electrical Engineering.
    search: Stanford University. Department of Electrical Engineering.
    pre_text: ''
    post_text: ''
    authorities:
    - http://id.loc.gov/authorities/names/nr2002030762
    rwo: []
marc_links_struct:
- version: '0.2'
  stanford_only: false
  stanford_law_only: false
  link_text:
  link_title: ''
  additional_text:
  additional_links: []
  access: ''
  material_type:
  note: ''
  href: https://purl.stanford.edu/bp098kt2063
  sort:
  casalini:
  fulltext: true
  managed_purl: true
  file_id:
  druid: bp098kt2063
  sfx: false
summary_struct:
- label: Summary
  fields:
  - field:
    - Deep neural networks face challenges in real-world deployment due to domain
      shifts and computational constraints. This dissertation presents TempT, a self-supervised
      method that leverages temporal smoothness in predictions to improve model robustness
      without labeled data. By suppressing high-frequency fluctuations, TempT enhances
      generalization, particularly in sequential tasks. We also explore selective
      adaptation using persistent homology to determine when adaptation is beneficial
      and introduce a regularization framework that enforces smoothness constraints
      during training. Experimental results demonstrate TempT's effectiveness over
      existing adaptation techniques while maintaining efficiency for edge computing
      and privacy-sensitive applications. This work unifies domain adaptation, self-supervised
      learning, and regularization to provide a scalable solution for deep learning
      in dynamic environments
    vernacular:
  unmatched_vernacular: []
holdings_json_struct:
- holdings:
  - id: 5b7b1c4c-c804-41fa-acf3-f827a4c86f8e
    hrid: ho00000413013
    notes: []
    _version: 1
    metadata:
      createdDate: '2025-03-14T20:37:20.756Z'
      updatedDate: '2025-03-14T20:37:20.756Z'
      createdByUserId: 709fdac6-d3f3-5784-8839-fe36ad6ed0b3
      updatedByUserId: 709fdac6-d3f3-5784-8839-fe36ad6ed0b3
    sourceId: f32d531e-df79-46b3-8932-cdd35f7a2264
    boundWith:
    formerIds: []
    illPolicy:
    instanceId: 4991c685-3832-4811-ac32-4843e33f36ea
    holdingsType:
      id: 996f93e2-5b5e-4cf2-9168-33ced1f95eed
      name: Electronic
      source: folio
    callNumberType:
    holdingsTypeId: 996f93e2-5b5e-4cf2-9168-33ced1f95eed
    electronicAccess: []
    holdingsStatements: []
    statisticalCodeIds: []
    administrativeNotes: []
    effectiveLocationId: 1b14e21c-8d47-45c7-bc49-456a0086422b
    permanentLocationId: 1b14e21c-8d47-45c7-bc49-456a0086422b
    suppressFromDiscovery: false
    holdingsStatementsForIndexes: []
    holdingsStatementsForSupplements: []
    location:
      effectiveLocation:
        id: 1b14e21c-8d47-45c7-bc49-456a0086422b
        code: SUL-SDR
        name: Stanford Digital Repository
        campus:
          id: c365047a-51f2-45ce-8601-e421ca3615c5
          code: SUL
          name: Stanford Libraries
        details: {}
        library:
          id: c1a86906-ced0-46cb-8f5b-8cef542bdd00
          code: SUL
          name: SUL
        isActive: true
        institution:
          id: 8d433cdd-4e8f-4dc1-aa24-8a4ddb7dc929
          code: SU
          name: Stanford University
      permanentLocation:
        id: 1b14e21c-8d47-45c7-bc49-456a0086422b
        code: SUL-SDR
        name: Stanford Digital Repository
        campus:
          id: c365047a-51f2-45ce-8601-e421ca3615c5
          code: SUL
          name: Stanford Libraries
        details: {}
        library:
          id: c1a86906-ced0-46cb-8f5b-8cef542bdd00
          code: SUL
          name: SUL
        isActive: true
        institution:
          id: 8d433cdd-4e8f-4dc1-aa24-8a4ddb7dc929
          code: SU
          name: Stanford University
  items: []
